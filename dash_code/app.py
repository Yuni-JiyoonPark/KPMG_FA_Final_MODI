# íŒŒì¼ëª…: app.py
from flask import Flask, render_template, request, redirect, url_for, jsonify, g, logging as flask_logging
import os
import sys #ëª¨ë“ˆì¶”ê°€ 
import json  # JSON íŒŒì‹±ì„ ìœ„í•´ ì¶”ê°€
import logging
import pandas as pd
from datetime import timedelta, datetime
from core.news_analyzer import NewsAnalyzer

# ê¸°ëŠ¥ ëª¨ë“ˆ ì„í¬íŠ¸
from app_modules import DashboardModule, NewsModule, MusinsaModule, MagazineModule

# ë¡œê¹… ì„¤ì •ì„ ë¨¼ì € ì‹¤í–‰
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í†µí•©ëœ all3ì˜ config import
import core.config as app_config

# --- RAG ì‹œìŠ¤í…œ ê´€ë ¨ import ë° ì´ˆê¸°í™” ---
# ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„ (ì ˆëŒ€ ê²½ë¡œ ë° ìƒëŒ€ ê²½ë¡œ)
rag_system = None
rag_system_initialized = False
searcher_paths = [
    '/Users/Admin/Desktop/rag/ê²€ìƒ‰ê¸°',  # ì ˆëŒ€ ê²½ë¡œ
    os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'ê²€ìƒ‰ê¸°')),  # ìƒëŒ€ ê²½ë¡œ (app.py íŒŒì¼ ê¸°ì¤€)
    os.path.join(os.getcwd(), '..', 'ê²€ìƒ‰ê¸°')  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€
]

# ê° ê²½ë¡œë¥¼ ì‹œë„í•˜ë©° ìœ íš¨í•œ ê²½ë¡œ ì°¾ê¸°
searcher_path = None
for path in searcher_paths:
    if os.path.isdir(path):
        searcher_path = path
        logger.info(f"'ê²€ìƒ‰ê¸°' í´ë”ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {path}")
        break

if not searcher_path:
    logger.error(f"CRITICAL: 'ê²€ìƒ‰ê¸°' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ê²½ë¡œ: {searcher_paths}")
else:
    # sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ import ê°€ëŠ¥í•˜ê²Œ í•¨
    if searcher_path not in sys.path:
        sys.path.insert(0, searcher_path)  # ìš°ì„ ìˆœìœ„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë§¨ ì•ì— ì¶”ê°€
        logger.info(f"sys.pathì— 'ê²€ìƒ‰ê¸°' ê²½ë¡œ ì¶”ê°€: {searcher_path}")

    try:
        from modi_rag import ModiRagSystem
        print("--- RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘ ---") # ì´ˆê¸°í™” ì‹œì‘ ë¡œê·¸ ì¶”ê°€
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œ í†µí•©ëœ app_config ì‚¬ìš©
        rag_system = ModiRagSystem(llm_api_key=app_config.LLM_API_KEY, llm_api_url=app_config.LLM_API_URL)
        print("ModiRagSystem ê°ì²´ ìƒì„± ì™„ë£Œ.")

        # --- ë°ì´í„° ë¡œë”© ì½”ë“œ ì¶”ê°€ ---
        try:
            print("--- RAG ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”© ì‹œì‘ ---")
            # ì„¤ì • íŒŒì¼(app_config)ì— ì •ì˜ëœ ê²½ë¡œ ì‚¬ìš©
            rag_system.load_data(
                fashion_path=app_config.FASHION_DOC_PATH,
                musinsa_path=app_config.MUSINSA_DOC_PATH,
                doc_vecs_path=app_config.DOC_VECS_PATH,
                ent_vecs_path=app_config.ENT_VECS_PATH
            )
            # ë‚ ì§œ ë°ì´í„° í™•ì¸ ë° í• ë‹¹ (ë°ì´í„° ë¡œë“œ í›„ ì‹¤í–‰)
            print("ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...") # ë‚ ì§œ ì²˜ë¦¬ ë¡œê·¸ ì¶”ê°€
            rag_system.ensure_date_data()
            print("--- RAG ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”© ë° ë‚ ì§œ í• ë‹¹ ì™„ë£Œ ---")
            rag_system_initialized = True # ë°ì´í„° ë¡œë“œ ì„±ê³µ ì‹œ ì´ˆê¸°í™” ì™„ë£Œë¡œ ê°„ì£¼
            logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë“œ ì™„ë£Œ (all3/app.py)")
        except FileNotFoundError as fnf_error:
            logger.error(f"RAG ë°ì´í„° íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ (íŒŒì¼ ì—†ìŒ): {fnf_error}", exc_info=True)
            rag_system_initialized = False
        except Exception as load_e:
            logger.error(f"RAG ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ (ê¸°íƒ€ ì˜¤ë¥˜): {load_e}", exc_info=True)
            rag_system_initialized = False # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ê°„ì£¼
        # --- ë°ì´í„° ë¡œë”© ì½”ë“œ ë ---

    except ImportError as e:
        logger.error(f"RAG ì‹œìŠ¤í…œ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}. 'ê²€ìƒ‰ê¸°' í´ë” ë‚´ modi_rag.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.", exc_info=True)
        logger.debug(f"í˜„ì¬ sys.path: {sys.path}")
    except Exception as e:
        logger.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ (all3/app.py): {e}", exc_info=True)
# --- RAG ì‹œìŠ¤í…œ ê´€ë ¨ ì½”ë“œ ë ---


# NewsAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
news_analyzer = NewsAnalyzer()

# ë¡œê¹… ì„¤ì • - ë””ë²„ê·¸ ë ˆë²¨ë¡œ ë³€ê²½
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
DATA_DIR = os.path.join('data')
os.makedirs(DATA_DIR, exist_ok=True)

# ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±
STATIC_DIR = os.path.join('static', 'images')
os.makedirs(STATIC_DIR, exist_ok=True)

# ê²½ìŸì‚¬ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
COMPETITOR_DIR = os.path.join('static', 'images', 'competitor')
os.makedirs(COMPETITOR_DIR, exist_ok=True)

# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = Flask(__name__, 
            static_folder='static',  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ static í´ë” ì§€ì •
            static_url_path='/static')  # URL ê²½ë¡œ ëª…ì‹œì  ì„¤ì •
app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-key-for-testing')

# ì •ì  íŒŒì¼ ìš”ì²­ ë¡œê¹… í™œì„±í™”
app.config['EXPLAIN_TEMPLATE_LOADING'] = True
app.config['DEBUG'] = True

# ê¸°ëŠ¥ ëª¨ë“ˆ ì´ˆê¸°í™”
dashboard_module = DashboardModule()
news_module = NewsModule()
musinsa_module = MusinsaModule()
magazine_module = MagazineModule()

# --- LLM ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜ ì¶”ê°€ ---
def parse_llm_report(report_content: str) -> dict:
    """LLMì´ ìƒì„±í•œ ë ˆí¬íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    parsed_data = {
        'trendInsight': 'íŒŒì‹±ëœ íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ ì˜ˆì‹œ',
        'buyingInsight': {'summary': 'íŒŒì‹±ëœ ë°”ì‰ ìš”ì•½', 'recommendations': [{'category': 'ìƒì˜', 'name': 'íŒŒì‹±ëœ ì•„ì´í…œ', 'reason': 'íŒŒì‹±ëœ ì´ìœ '}]},
        'sellingInsight': {'summary': 'íŒŒì‹±ëœ ì…€ë§ ìš”ì•½', 'keywords': [{'text': 'íŒŒì‹±í‚¤ì›Œë“œ', 'stats': 'íŒŒì‹± í†µê³„'}]},
        'keywordReports': []  # ìƒì„¸ ë¦¬í¬íŠ¸ íŒŒì‹± ë¡œì§ ì¶”ê°€ í•„ìš”
    }

    try:
        # ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ íŒŒì‹± ì˜ˆì‹œ
        sections = report_content.split('###')
        for section in sections:
            section = section.strip()
            if section.startswith('ğŸ“Œ ì¸ê¸° í‚¤ì›Œë“œ'):
                pass  # ì´ë¯¸ topKeywordsë¡œ ì²˜ë¦¬ë¨
            elif section.startswith('ğŸ§  ë¦¬í¬íŠ¸ ì‘ì„± ì§€ì‹œì‚¬í•­'):
                break  # ì§€ì‹œì‚¬í•­ ì´í›„ëŠ” íŒŒì‹± ëŒ€ìƒ ì•„ë‹˜
            elif section.startswith('1. [íŠ¸ë Œë“œ í‚¤ì›Œë“œ ë° ì„¤ëª…]'):
                # ì²« ì¤„ ì œì™¸í•˜ê³  ë‚´ìš© ì¶”ì¶œ
                lines = section.split('\n', 1)
                if len(lines) > 1:
                    parsed_data['trendInsight'] = lines[1].strip()
            elif section.startswith('8. [ë°”ì‰ MD ì „ëµ ì œì•ˆ]'):
                lines = section.split('\n', 1)
                if len(lines) > 1:
                    # ë°”ì‰/ì…€ë§ ì¸ì‚¬ì´íŠ¸ëŠ” ë” ë³µì¡í•œ íŒŒì‹± í•„ìš”
                    # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ ìš”ì•½ë§Œ ë„£ìŒ
                    parsed_data['buyingInsight']['summary'] = lines[1].strip()[:100] + "..."  # ì²« 100ìë§Œ ì‚¬ìš©
                    parsed_data['sellingInsight']['summary'] = lines[1].strip()[:100] + "..."  # ì²« 100ìë§Œ ì‚¬ìš©

        # ê°„ë‹¨í•œ ì˜ˆì‹œ í‚¤ì›Œë“œ ë¦¬í¬íŠ¸ ì¶”ê°€
        for i in range(5):
            parsed_data['keywordReports'].append({
                'keyword': f'í‚¤ì›Œë“œ{i+1}',
                'summary': f'í‚¤ì›Œë“œ{i+1}ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤.'
            })

    except Exception as parse_error:
        logger.error(f"LLM ë ˆí¬íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {parse_error}")
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€

    # ê¸°ë³¸ê°’ì´ ì—†ëŠ” ê²½ìš° ì±„ìš°ê¸°
    parsed_data.setdefault('trendInsight', 'íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
    parsed_data.setdefault('buyingInsight', {'summary': 'ë°”ì‰ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜', 'recommendations': []})
    parsed_data.setdefault('sellingInsight', {'summary': 'ì…€ë§ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜', 'keywords': []})
    parsed_data.setdefault('keywordReports', [{'keyword': f'í‚¤ì›Œë“œ{i+1}', 'summary': 'ìƒì„¸ ë¦¬í¬íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜'} for i in range(5)])

    return parsed_data
# --- íŒŒì‹± í•¨ìˆ˜ ë ---

# ê¸°ëŠ¥ ëª¨ë“ˆ ì´ˆê¸°í™”
dashboard_module = DashboardModule()
news_module = NewsModule()
musinsa_module = MusinsaModule()
magazine_module = MagazineModule()

@app.before_request
def set_global_period():
    """ëª¨ë“  ìš”ì²­ ì „ì— ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜, ì „ì—­ ê¸°ê°„ ì„¤ì •"""
    # ì •ì  íŒŒì¼ ìš”ì²­ì€ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
    if request.path.startswith('/static/'):
        return
        
    # URLì—ì„œ period íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    g.period = request.args.get('period', '7ì¼')
    g.start_date = request.args.get('start_date')
    g.end_date = request.args.get('end_date')
    
    # ë””ë²„ê·¸ ë¡œê¹… - ìš”ì²­ ì •ë³´
    logger.debug(f"ìš”ì²­ ê²½ë¡œ: {request.path}, ìš”ì²­ ì¸ì: {dict(request.args)}")
    
    # ìœ íš¨í•œ period ê°’ í™•ì¸
    valid_periods = ['7ì¼', '2ì£¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', '1ì£¼ì¼', 'custom']
    if g.period not in valid_periods:
        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ê°„({g.period})ì´ ìš”ì²­ë˜ì–´ ê¸°ë³¸ê°’(7ì¼)ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        g.period = '7ì¼'
    
    # custom ê¸°ê°„ ì„¤ì • ì‹œ start_dateì™€ end_date í™•ì¸
    if g.period == 'custom' and (not g.start_date or not g.end_date):
        logger.warning("custom ê¸°ê°„ì´ ì„ íƒë˜ì—ˆìœ¼ë‚˜ ì‹œì‘ì¼ ë˜ëŠ” ì¢…ë£Œì¼ì´ ì—†ì–´ ê¸°ë³¸ê°’(7ì¼)ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        g.period = '7ì¼'
        g.start_date = None
        g.end_date = None
    
    logger.info(f"ì „ì—­ ê¸°ê°„ ì„¤ì •: period={g.period}, start_date={g.start_date}, end_date={g.end_date}")

@app.before_request
def log_request_info():
    # ì •ì  íŒŒì¼ ìš”ì²­ì¸ ê²½ìš°ë§Œ ë¡œê¹…
    if request.path.startswith('/static/'):
        logger.debug(f"ì •ì  íŒŒì¼ ìš”ì²­: {request.path}")

# ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ì¸ë±ì‹± ìš”ì²­ ì²˜ë¦¬
@app.route('/static/')
@app.route('/static/<path:directory>')
def handle_directory_index(directory=''):
    """ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ì¸ë±ìŠ¤ ìš”ì²­ ì²˜ë¦¬"""
    if not directory or directory.endswith('/'):
        logger.debug(f"ì •ì  ë””ë ‰í† ë¦¬ ì¸ë±ìŠ¤ ìš”ì²­ ë¦¬ë‹¤ì´ë ‰íŠ¸: {directory}")
        # ë©”ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return redirect(url_for('dashboard'))
    return app.send_static_file(directory)

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€ - ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    return redirect(url_for('dashboard'))

@app.route('/dashboard')
def dashboard():
    """í†µí•© ëŒ€ì‹œë³´ë“œ"""
    try:
        # ê¸°ê°„ ì„¤ì •
        if g.period == 'custom' and g.start_date and g.end_date:
            period = 'custom'
            start_date = g.start_date
            end_date = g.end_date
        else:
            period = g.period
            start_date = None
            end_date = None

                # í˜„ì¬ ì‹œê°„ (ìºì‹œ ë°©ì§€ìš©)
        now = datetime.now()

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì „ë‹¬
        if not rag_system_initialized:
            error_msg = "ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            return render_template('dashboard.html',
                               error=error_msg,
                               period=period,
                               display_period=display_period,
                               start_date=start_date,
                               end_date=end_date,
                               now=now)
        
        # í˜„ì¬ ì‹œê°„ (ìºì‹œ ë°©ì§€ìš©)
        now = datetime.now()
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        news_data_loader = news_module.data_loader
        magazine_data_loader = magazine_module.data_loader
        musinsa_data_loader = musinsa_module.data_loader
        
        # ë°ì´í„° ë¡œë“œ
        if period == 'custom' and start_date and end_date:
            data = news_data_loader.load_data_by_date_range(start_date, end_date)
            magazine_data = magazine_data_loader.load_data_by_date_range(start_date, end_date)
            musinsa_data = musinsa_data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_data_loader.load_data_by_period(period)
            magazine_data = magazine_data_loader.load_data_by_period(period)
            musinsa_data = musinsa_data_loader.load_data_by_period(period)
        
        # í†µí•© íŠ¸ë Œë“œ API í˜¸ì¶œ
        api_url = f"/api/integrated-trends?period={period}"
        if period == 'custom' and start_date and end_date:
            api_url += f"&start_date={start_date}&end_date={end_date}"
        
        try:
            # ë‚´ë¶€ì ìœ¼ë¡œ API í˜¸ì¶œ (app_context ë‚´ì—ì„œ ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ)
            with app.test_request_context(api_url):
                trends_data = integrated_trends().get_json()
        except Exception as e:
            logger.error(f"í†µí•© íŠ¸ë Œë“œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
            trends_data = {}
        
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if data is None or data.empty:
            data = pd.DataFrame()  # ë¹ˆ DataFrameìœ¼ë¡œ ì´ˆê¸°í™”
        
        # ê¸°ì¡´ ì‹œê°í™” ë°ì´í„° ë¡œë“œ
        fig_network = dashboard_module.generate_network_graph(data) if not data.empty else None
        fig_category = dashboard_module.generate_category_chart(data) if not data.empty else None
        fig_wordcloud = dashboard_module.generate_wordcloud(data) if not data.empty else None
        
        # APIì—ì„œ ë°˜í™˜í•œ ë°ì´í„° ì‚¬ìš©
        top_keywords = trends_data.get('topKeywords', [])
        keyword_reports = trends_data.get('keywordReports', [])
        trend_insight = trends_data.get('trendInsight', '')
        buying_insight = trends_data.get('buyingInsight', {}).get('summary', '')
        selling_insight = trends_data.get('sellingInsight', {}).get('summary', '')
        
        # ë””ìŠ¤í”Œë ˆì´ìš© ê¸°ê°„ ë¬¸ìì—´
        if period == 'custom' and start_date and end_date:
            display_period = f"{start_date} ~ {end_date}"
        else:
            display_period = period
        
        # í˜„ì¬ ì›” ì •ë³´
        current_month = now.strftime('%Yë…„ %mì›”')
        
        return render_template('dashboard.html',
                              period=period,
                              display_period=display_period,
                              start_date=start_date,
                              end_date=end_date,
                              fig_network=fig_network,
                              fig_category=fig_category,
                              fig_wordcloud=fig_wordcloud,
                              top_keywords=top_keywords,
                              keyword_reports=keyword_reports,
                              trend_insight=trend_insight,
                              buying_insight=buying_insight,
                              selling_insight=selling_insight,
                              current_month=current_month,
                              now=now,
                              events=trends_data.get('events', []))
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ ë Œë”ë§ ì˜¤ë¥˜: {e}", exc_info=True)
        return render_template('dashboard.html',
                              error="ëŒ€ì‹œë³´ë“œ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                              period=g.period,
                              start_date=g.start_date,
                              end_date=g.end_date,
                              now=datetime.now())

@app.route('/news')
def news():
    """ë‰´ìŠ¤ ë¶„ì„ í˜ì´ì§€"""
    try:
        # ì…ë ¥ê°’ ê²€ì¦
        if g.period == 'custom':
            if not (g.start_date and g.end_date) or g.start_date == 'None' or g.end_date == 'None':
                # í˜„ì¬ ë‚ ì§œì™€ 30ì¼ ì „ ë‚ ì§œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                # ê¸°ë³¸ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
                g.period = '1ê°œì›”'
                logger.info(f"ë‚ ì§œ None ê°’ ëŒ€ì‹  ê¸°ë³¸ê°’ ì‚¬ìš©: {start_date} ~ {end_date}")
            else:
                try:
                    start_date = pd.to_datetime(g.start_date).strftime('%Y-%m-%d')
                    end_date = pd.to_datetime(g.end_date).strftime('%Y-%m-%d')
                except Exception as e:
                    # í˜„ì¬ ë‚ ì§œì™€ 30ì¼ ì „ ë‚ ì§œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                    end_date = datetime.now().strftime('%Y-%m-%d')
                    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                    # ê¸°ë³¸ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
                    g.period = '1ê°œì›”'
                    logger.warning(f"ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
                
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
            display_period = f"{start_date} ~ {end_date}"
            # ...ê¸°ì¡´ ì½”ë“œ...
        else:
            if g.period not in ['7ì¼', '2ì£¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„']:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ê°„: {g.period}, ê¸°ë³¸ê°’ '7ì¼'ë¡œ ì„¤ì •")
                g.period = '7ì¼'
            data = news_module.data_loader.load_data_by_period(g.period)
            display_period = g.period

        # í˜„ì¬ ì‹œê°„ ì¶”ê°€ (JS ìºì‹œ ë°©ì§€ìš©)
        from datetime import datetime
        now = datetime.now()

        if data is None or data.empty:
            return render_template('news.html',
                               error="í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                               period=g.period,
                               start_date=g.start_date,
                               end_date=g.end_date,
                               news_articles=[],
                               now=now)  # í˜„ì¬ ì‹œê°„ ì¶”ê°€

        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_module.analyzer.set_data(data)
        
        # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
        dashboard_data = news_module.analyzer.generate_dashboard_data()
        
        # ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬
        latest_articles = data.sort_values('published', ascending=False).head(10).to_dict('records')
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        freq_results = news_module.analyzer.analyze_word_frequency()
        top_keywords = news_module.analyzer.get_top_words(freq_results, top_n=5)
        
        # ê°ì„± ë¶„ì„
        sentiment_df = news_module.analyzer.calculate_article_sentiment()
        sentiment_results = news_module.analyzer.get_sentiment_distribution(sentiment_df)
        
        # ê¸ì •/ë¶€ì • ê¸°ì‚¬
        positive_articles = sentiment_results['positive_articles'][:3] if sentiment_results else []
        negative_articles = sentiment_results['negative_articles'][:3] if sentiment_results else []
        
        return render_template('news.html',
                            period=g.period,
                            display_period=display_period,
                            start_date=g.start_date,
                            end_date=g.end_date,
                            latest_articles=latest_articles,
                            top_keywords=top_keywords,
                            keyword_trend=dashboard_data.get('keyword_trend'),
                            tfidf_wordcloud=dashboard_data.get('wordcloud'),
                            keyword_network=dashboard_data.get('keyword_network'),
                            positive_articles=positive_articles,
                            negative_articles=negative_articles,
                            now=now)  # í˜„ì¬ ì‹œê°„ ì¶”ê°€

    except ValueError as e:
        logger.error(f"ì…ë ¥ê°’ ì˜¤ë¥˜: {e}")
        return render_template('news.html',
                            error=str(e),
                            period=g.period,
                            start_date=g.start_date,
                            end_date=g.end_date,
                            news_articles=[],
                            now=datetime.now())  # í˜„ì¬ ì‹œê°„ ì¶”ê°€
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return render_template('news.html',
                            error="ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                            period=g.period,
                            start_date=g.start_date,
                            end_date=g.end_date,
                            news_articles=[],
                            now=datetime.now())  # í˜„ì¬ ì‹œê°„ ì¶”ê°€

@app.route('/musinsa')
def musinsa():
    """ë¬´ì‹ ì‚¬ ê²½ìŸì‚¬ ë¶„ì„ í˜ì´ì§€"""
    try:
        # CSV ì§ì ‘ ë¡œë“œë¡œ ë³€ê²½
        if g.period == 'custom' and g.start_date and g.end_date:
            return musinsa_module.render_musinsa(
                period='custom', 
                start_date=g.start_date, 
                end_date=g.end_date
            )
        
        return musinsa_module.render_musinsa(period=g.period)
    
    except Exception as e:
        logger.error(f"ë¬´ì‹ ì‚¬ í˜ì´ì§€ ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        return render_template('musinsa.html', error="ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.route('/magazine')
def magazine():
    """ë§¤ê±°ì§„ ë¶„ì„ í˜ì´ì§€"""
    # URLì—ì„œ ì„ íƒëœ ë§¤ê±°ì§„ ê°€ì ¸ì˜¤ê¸°
    selected_magazines = request.args.getlist('magazine')
    
    # ì„ íƒëœ ë§¤ê±°ì§„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
    if not selected_magazines:
        selected_magazines = ['jentestore', 'marieclaire', 'vogue', 'wkorea', 'wwdkorea']
    
    if g.period == 'custom' and g.start_date and g.end_date:
        return magazine_module.render_magazine(
            period='custom', 
            start_date=g.start_date, 
            end_date=g.end_date,
            selected_magazines=selected_magazines
        )
    
    return magazine_module.render_magazine(
        period=g.period,
        selected_magazines=selected_magazines
    )

@app.route('/api/keywords')
def get_keywords():
    """í‚¤ì›Œë“œ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        data_loader = dashboard_module.data_loader
        
        if period == 'custom' and start_date and end_date:
            data = data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("í‚¤ì›Œë“œ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify([])
        
        all_tokens = []
        if 'tokens' in data.columns:
            for tokens in data['tokens']:
                if isinstance(tokens, list):
                    all_tokens.extend(tokens)
        
        if not all_tokens:
            logger.warning("í‚¤ì›Œë“œ API: í† í° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify([])
            
        token_counts = pd.Series(all_tokens).value_counts().head(20)
        
        keywords = [{'text': key, 'count': int(value)} 
                   for key, value in token_counts.items()]
        
        return jsonify(keywords)
    
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ API ì˜¤ë¥˜: {e}")
        return jsonify([])

@app.route('/api/magazine-data')
def get_magazine_data():
    """ë§¤ê±°ì§„ ë°ì´í„° API"""
    try:
        magazine = request.args.get('magazine')
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        if not magazine:
            return jsonify({'error': 'ë§¤ê±°ì§„ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.'})
        
        data_loader = magazine_module.data_loader
        
        if period == 'custom' and start_date and end_date:
            data = data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = data_loader.load_data_by_period(period)
            
        if data is None or data.empty:
            logger.warning(f"ë§¤ê±°ì§„ ë°ì´í„° API: {magazine}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        keywords = data_loader.get_magazine_keywords(magazine)
        card_news = data_loader.get_card_news(magazine)
        
        return jsonify({
            'keywords': keywords,
            'card_news': card_news
        })
    
    except Exception as e:
        logger.error(f"ë§¤ê±°ì§„ ë°ì´í„° API ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)})

@app.route('/api/category-data')
def category_data():
    """ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° API"""
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ë¡œê¹… (ë””ë²„ê¹…ìš©)
        logger.debug(f"ì¹´í…Œê³ ë¦¬ ë°ì´í„° API ìš”ì²­ íŒŒë¼ë¯¸í„°: {dict(request.args)}")
        
        category_type = request.args.get('type', 'item')
        period = request.args.get('period') or g.period
        start_date = request.args.get('start_date') or g.start_date
        end_date = request.args.get('end_date') or g.end_date
        
        logger.info(f"ì¹´í…Œê³ ë¦¬ ë°ì´í„° API: íƒ€ì…={category_type}, ê¸°ê°„={period}, ì‹œì‘ì¼={start_date}, ì¢…ë£Œì¼={end_date}")
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        data_loader = magazine_module.data_loader
        
        # custom ê¸°ê°„ì¸ ê²½ìš° ì‹œì‘/ì¢…ë£Œì¼ ì„¤ì •
        if period == 'custom' and start_date and end_date:
            data_loader.custom_start_date = start_date
            data_loader.custom_end_date = end_date
            logger.info(f"ì§ì ‘ ì„¤ì • ê¸°ê°„ ì‚¬ìš©: {start_date} ~ {end_date}")
        
        # ì¹´í…Œê³ ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        category_data = data_loader.get_category_data(category_type, period)
        
        if not category_data:
            # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
            logger.warning(f"ì¹´í…Œê³ ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: íƒ€ì…={category_type}, ê¸°ê°„={period}")
            return jsonify({
                'categories': ['ë°ì´í„° ì—†ìŒ'],
                'counts': [0],
                'growth_rates': [0],
                'prev_counts': [0]
            })
        
        return jsonify(category_data)
    
    except Exception as e:
        logger.error(f"ì¹´í…Œê³ ë¦¬ ë°ì´í„° API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})
    
@app.route('/api/brand-details')
def brand_details():
    try:
        brand_name = request.args.get('brand')
        if not brand_name:
            return jsonify({"error": "ë¸Œëœë“œëª…ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ë°ì´í„° ìºì‹± ê³ ë ¤
        file_path = os.path.join('data', 'musinsa_data.csv')
        df = pd.read_csv(file_path, encoding='utf-8')
        
        # ë°ì´í„° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        brand_data = df[df['brand'] == brand_name]
        
        if brand_data.empty:
            return jsonify({"error": f"{brand_name} ë¸Œëœë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        details = {
            'name': brand_name,
            'category': _get_safe_mode(brand_data['category']),
            'gender': _get_safe_unique_list(brand_data['gender']),
            'price_info': _get_price_range_info(brand_data),
            'rating_info': _get_rating_info(brand_data),
            'review_info': _get_review_info(brand_data),
            'product_details': _get_product_sample(brand_data)
        }
        
        return jsonify(details)
    
    except Exception as e:
        logger.error(f"ë¸Œëœë“œ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({"error": "ì„œë²„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}), 500

def _get_safe_mode(series):
    """ì‹œë¦¬ì¦ˆì˜ ìµœë¹ˆê°’ì„ ì•ˆì „í•˜ê²Œ ë°˜í™˜"""
    try:
        return series.mode().values[0] if not series.empty else "ì •ë³´ ì—†ìŒ"
    except:
        return "ì •ë³´ ì—†ìŒ"

def _get_safe_unique_list(series):
    """ê³ ìœ ê°’ ë¦¬ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ë°˜í™˜"""
    try:
        unique_values = series.unique().tolist()
        return unique_values if unique_values else ["ì •ë³´ ì—†ìŒ"]
    except:
        return ["ì •ë³´ ì—†ìŒ"]

def _get_price_range_info(brand_data):
    """ê°€ê²© ì •ë³´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
    try:
        # ê°€ê²© ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ
        prices = brand_data['price'].str.replace(',', '').str.replace('ì›', '').astype(int)
        return {
            'min_price': f"{prices.min():,}ì›",
            'max_price': f"{prices.max():,}ì›",
            'avg_price': f"{int(prices.mean()):,}ì›"
        }
    except Exception as e:
        logger.warning(f"ê°€ê²© ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {
            'min_price': 'ì •ë³´ ì—†ìŒ',
            'max_price': 'ì •ë³´ ì—†ìŒ', 
            'avg_price': 'ì •ë³´ ì—†ìŒ'
        }

def _get_rating_info(brand_data):
    """í‰ì  ì •ë³´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
    try:
        return {
            'avg_rating': f"{brand_data['rating'].mean():.2f}",
            'rating_count': len(brand_data[brand_data['rating'] > 0])
        }
    except Exception as e:
        logger.warning(f"í‰ì  ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {
            'avg_rating': '0.00',
            'rating_count': 0
        }

def _get_review_info(brand_data):
    """ë¦¬ë·° ì •ë³´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
    try:
        return {
            'total_reviews': int(brand_data['review_count'].sum()),
            'avg_reviews_per_product': f"{brand_data['review_count'].mean():.1f}"
        }
    except Exception as e:
        logger.warning(f"ë¦¬ë·° ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {
            'total_reviews': 0,
            'avg_reviews_per_product': '0.0'
        }

def _get_product_sample(brand_data, n=5):
    """ëŒ€í‘œ ìƒí’ˆ ìƒ˜í”Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
    try:
        # ë¦¬ë·° ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒ˜í”Œ ì¶”ì¶œ
        sample_products = []
        sorted_data = brand_data.sort_values('review_count', ascending=False).head(n)
        
        for _, row in sorted_data.iterrows():
            sample_products.append({
                'name': row.get('name', 'ìƒí’ˆëª… ì—†ìŒ'),
                'price': row.get('price', 'ê°€ê²© ì •ë³´ ì—†ìŒ'),
                'review_count': int(row.get('review_count', 0)),
                'link': row.get('link', '#')
            })
        
        return sample_products
    except Exception as e:
        logger.warning(f"ëŒ€í‘œ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

#ë‰´ìŠ¤ ê´€ë ¨ ë¼ìš°íŠ¸ ì¶”ê°€
@app.route('/api/news/tfidf')
def api_news_tfidf():
    """ë‰´ìŠ¤ TF-IDF ë¶„ì„ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("TF-IDF API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_analyzer.set_data(data)
        
        # TF-IDF ë¶„ì„ ì‹¤í–‰
        tfidf_results = news_analyzer.analyze_tfidf()
        
        # TF-IDF ì°¨íŠ¸ ìƒì„±
        tfidf_chart = news_analyzer.generate_tfidf_chart(top_n=20, tfidf_results=tfidf_results)
        
        # TF-IDF ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        tfidf_wordcloud = news_analyzer.generate_tfidf_wordcloud(tfidf_results=tfidf_results)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'chart': tfidf_chart,
            'wordcloud': tfidf_wordcloud
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"TF-IDF API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/news/topics')
def api_news_topics():
    """ë‰´ìŠ¤ í† í”½ ëª¨ë¸ë§ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("í† í”½ ëª¨ë¸ë§ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_analyzer.set_data(data)
        
        # í† í”½ ê°œìˆ˜ íŒŒë¼ë¯¸í„°
        n_topics = request.args.get('n_topics', default=5, type=int)
        
        # í† í”½ ëª¨ë¸ë§ ì‹¤í–‰
        topic_results = news_analyzer.analyze_topics(n_topics=n_topics)
        
        # í† í”½ ë¶„í¬ ì •ë³´
        topic_distribution = news_analyzer.get_topic_distribution(topic_results)
        
        # í† í”½ ì°¨íŠ¸ ìƒì„±
        topic_charts = news_analyzer.generate_topic_chart(topic_results)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'topic_info': topic_distribution['topic_info'] if topic_distribution else None,
            'charts': topic_charts
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"í† í”½ ëª¨ë¸ë§ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/news/sentiment')
def api_news_sentiment():
    """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("ê°ì„± ë¶„ì„ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_analyzer.set_data(data)
        
        # ê°ì„± ë¶„ì„ ì‹¤í–‰
        sentiment_df = news_analyzer.calculate_article_sentiment()
        
        # ê°ì„± ë¶„í¬ ì •ë³´
        sentiment_distribution = news_analyzer.get_sentiment_distribution(sentiment_df)
        
        # ê°ì„± ì°¨íŠ¸ ìƒì„±
        sentiment_charts = news_analyzer.generate_sentiment_chart(sentiment_df)
        
        # ê°ì„± ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        sentiment_wordclouds = news_analyzer.get_sentiment_wordcloud(sentiment_df)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'sentiment_counts': sentiment_distribution['sentiment_counts'] if sentiment_distribution else None,
            'positive_articles': sentiment_distribution['positive_articles'][:3] if sentiment_distribution else [],
            'negative_articles': sentiment_distribution['negative_articles'][:3] if sentiment_distribution else [],
            'charts': sentiment_charts,
            'wordclouds': sentiment_wordclouds
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"ê°ì„± ë¶„ì„ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/news/search')
def api_news_search():
    """ë‰´ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ
        keyword = request.args.get('keyword')
        if not keyword:
            return jsonify({'error': 'ê²€ìƒ‰ í‚¤ì›Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.'})
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("ê²€ìƒ‰ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # í‚¤ì›Œë“œë¡œ ê¸°ì‚¬ í•„í„°ë§
        if 'token_list' in data.columns:
            # í† í°ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            matches = data['token_list'].apply(lambda tokens: keyword in tokens if isinstance(tokens, list) else False)
        elif 'tokens' in data.columns:
            # í† í°ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            matches = data['tokens'].apply(lambda tokens: keyword in tokens if isinstance(tokens, list) else False)
        else:
            # ì œëª©ì´ë‚˜ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            matches = (
                data['title'].str.contains(keyword, case=False, na=False) | 
                data['content'].str.contains(keyword, case=False, na=False)
            )
        
        matched_articles = data[matches].sort_values('upload_date', ascending=False)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'keyword': keyword,
            'total_matches': len(matched_articles),
            'articles': matched_articles.head(10).to_dict('records')
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/news/network')
def api_news_network():
    """ë‰´ìŠ¤ ë‹¨ì–´ ì—°ê´€ì„± ë„¤íŠ¸ì›Œí¬ API"""
    try:
        period = g.period
        start_date = g.start_date
        end_date = g.end_date
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("ë„¤íŠ¸ì›Œí¬ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_analyzer.set_data(data)
        
        # ì—°ê´€ì„± ë¶„ì„ ì‹¤í–‰
        association_results = news_analyzer.analyze_word_association()
        
        # ì¤‘ì‹¬ ë‹¨ì–´ ì¶”ì¶œ
        central_words = news_analyzer.get_central_words(association_results)
        
        # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
        network_graph = news_analyzer.generate_network_graph(association_results)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'central_words': central_words,
            'network_graph': network_graph
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"ë„¤íŠ¸ì›Œí¬ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/news/trend')
def api_news_trend():
    """ë‰´ìŠ¤ ì‹œê³„ì—´ íŠ¸ë Œë“œ API"""
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        period = request.args.get('period', g.period)
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        
        # None ê°’ í™•ì¸ ë° ì²˜ë¦¬
        if start_date == 'None' or start_date == '' or start_date is None:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
            if period == 'custom':
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                period = '1ê°œì›”'  # ê¸°ë³¸ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
                logger.info(f"API: ë‚ ì§œ None ê°’ ëŒ€ì‹  ê¸°ë³¸ê°’ ì‚¬ìš©: {start_date} ~ {end_date}")
            else:
                start_date = None
        
        if end_date == 'None' or end_date == '' or end_date is None:
            if period == 'custom':
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                period = '1ê°œì›”'  # ê¸°ë³¸ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
                logger.info(f"API: ë‚ ì§œ None ê°’ ëŒ€ì‹  ê¸°ë³¸ê°’ ì‚¬ìš©: {start_date} ~ {end_date}")
            else:
                end_date = None
        
        logger.info(f"ì‹œê³„ì—´ íŠ¸ë Œë“œ API í˜¸ì¶œ: ê¸°ê°„={period}, ì‹œì‘ì¼={start_date}, ì¢…ë£Œì¼={end_date}")
        
        # NewsModuleì—ì„œ ë°ì´í„° ë¡œë“œ
        data = None
        
        if period == 'custom' and start_date and end_date:
            try:
                # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                pd.to_datetime(start_date)
                pd.to_datetime(end_date)
                data = news_module.data_loader.load_data_by_date_range(start_date, end_date)
            except Exception as e:
                logger.error(f"ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
                return jsonify({'error': f'ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}'})
        else:
            data = news_module.data_loader.load_data_by_period(period)
        
        if data is None or data.empty:
            logger.warning("íŠ¸ë Œë“œ API: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        # NewsAnalyzerì— ë°ì´í„° ì„¤ì •
        news_analyzer.set_data(data)
        
        # ì‹œê³„ì—´ ë‹¨ìœ„
        time_unit = request.args.get('unit', default='monthly')
        
        logger.info(f"ì‹œê³„ì—´ ë¶„ì„ ë‹¨ìœ„: {time_unit}")
        
        # ì‹œê³„ì—´ ë¶„ì„ ì‹¤í–‰
        time_data = news_analyzer.analyze_time_series()
        
        if not time_data:
            logger.warning("ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
            return jsonify({'error': 'ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
        
        # ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±
        time_chart = news_analyzer.generate_time_series_chart(time_data=time_data, time_unit=time_unit)
        
        # í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ)
        top_keywords = []
        
        try:
            freq_results = news_analyzer.analyze_word_frequency()
            
            if not freq_results or 'word_counts' not in freq_results:
                logger.warning("ë‹¨ì–´ ë¹ˆë„ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return jsonify({
                    'time_chart': time_chart,
                    'error': 'í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'
                })
            
            top_keywords = [word for word, _ in freq_results['word_counts'].most_common(5)]
            
            logger.info(f"ìƒìœ„ í‚¤ì›Œë“œ: {top_keywords}")
            
            # í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ (ê°œì„ ëœ ë²„ì „)
            keyword_trend_data = news_analyzer.analyze_keyword_trend(top_keywords, time_unit)
            
            if keyword_trend_data is None:
                logger.warning("í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„°ê°€ Noneì…ë‹ˆë‹¤.")
                return jsonify({
                    'time_chart': time_chart,
                    'error': 'í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'top_keywords': top_keywords
                })
            
            # ë°ì´í„° êµ¬ì¡° ë¡œê¹…
            if keyword_trend_data:
                logger.info(f"í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„° êµ¬ì¡°: {list(keyword_trend_data.keys())}")
                if 'trends' in keyword_trend_data:
                    logger.info(f"íŠ¸ë Œë“œ í‚¤: {list(keyword_trend_data['trends'].keys())}")
            
            # í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„± (ê°œì„ ëœ ë²„ì „)
            keyword_trend_chart = news_analyzer.generate_keyword_trend_chart(top_keywords, keyword_trend_data)
            
            if keyword_trend_chart is None:
                logger.warning("í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨")
                return jsonify({
                    'time_chart': time_chart,
                    'error': 'í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'top_keywords': top_keywords
                })
            
            logger.info(f"í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return jsonify({
                'time_chart': time_chart,
                'error': f'í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'top_keywords': top_keywords
            })
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'time_chart': time_chart,
            'keyword_trend': keyword_trend_chart,
            'top_keywords': top_keywords
        }
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"íŠ¸ë Œë“œ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})
    
# app.pyì— ì¶”ê°€í•  ë¼ìš°íŠ¸

@app.route('/api/integrated-trends')
def integrated_trends():
    """í†µí•© íŠ¸ë Œë“œ ë¶„ì„ API"""
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„°
        period = request.args.get('period', '7ì¼')
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        
        logger.info(f"í†µí•© íŠ¸ë Œë“œ ìš”ì²­: ê¸°ê°„={period}, ì‹œì‘ì¼={start_date}, ì¢…ë£Œì¼={end_date}")
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        news_data_loader = news_module.data_loader
        magazine_data_loader = magazine_module.data_loader
        musinsa_data_loader = musinsa_module.data_loader
        
        # ë°ì´í„° ë¡œë“œ
        if period == 'custom' and start_date and end_date:
            news_data = news_data_loader.load_data_by_date_range(start_date, end_date)
            magazine_data = magazine_data_loader.load_data_by_date_range(start_date, end_date)
            musinsa_data = musinsa_module.data_loader.load_data_by_date_range(start_date, end_date)
        else:
            news_data = news_data_loader.load_data_by_period(period)
            magazine_data = magazine_data_loader.load_data_by_period(period)
            musinsa_data = musinsa_module.data_loader.load_data_by_period(period)
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if news_data is None or news_data.empty:
            logger.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            news_data = pd.DataFrame()
        
        if magazine_data is None or magazine_data.empty:
            logger.warning("ë§¤ê±°ì§„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            magazine_data = pd.DataFrame()
            
        if musinsa_data is None or musinsa_data.empty:
            logger.warning("ë¬´ì‹ ì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            musinsa_data = pd.DataFrame()
        
        # ëª¨ë“  ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        if news_data.empty and magazine_data.empty and musinsa_data.empty:
            return jsonify({
                'error': 'í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
                'topKeywords': []
            })
        
        # í†µí•© ë°ì´í„° ì¤€ë¹„
        combined_tokens = []
        
        # ë‰´ìŠ¤ í† í° ì¶”ì¶œ
        if not news_data.empty and 'token_list' in news_data.columns:
            for tokens in news_data['token_list']:
                if isinstance(tokens, list):
                    combined_tokens.extend(tokens)
        
        # ë§¤ê±°ì§„ í† í° ì¶”ì¶œ
        if not magazine_data.empty and 'tokens' in magazine_data.columns:
            for tokens in magazine_data['tokens']:
                if isinstance(tokens, list):
                    combined_tokens.extend(tokens)
        
        # ë¬´ì‹ ì‚¬ í† í° ì¶”ì¶œ (ì ì ˆí•œ ì»¬ëŸ¼ëª… ê°€ì •)
        if not musinsa_data.empty and 'tokens' in musinsa_data.columns:
            for tokens in musinsa_data['tokens']:
                if isinstance(tokens, list):
                    combined_tokens.extend(tokens)
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        from collections import Counter
        token_counter = Counter(combined_tokens)
        top_keywords = token_counter.most_common(10)
        
        # GPT/Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ í‚¤ì›Œë“œ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
        
        # ì˜ˆì‹œ ì‘ë‹µ ë°ì´í„°
        response_data = {
            'topKeywords': [
                {'text': kw, 'count': count, 'description': f"'{kw}' í‚¤ì›Œë“œëŠ” í˜„ì¬ íŠ¸ë Œë“œì—ì„œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤."} 
                for kw, count in top_keywords
            ],
            'trendInsight': "í˜„ì¬ íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì´ë²ˆ ì‹œì¦Œì—ëŠ” ë¯¸ë‹ˆë©€í•œ ë””ìì¸ê³¼ ì§€ì†ê°€ëŠ¥í•œ íŒ¨ì…˜ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.",
            'buyingInsight': {
                'summary': "íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼, ë‹¤ìŒ ìƒí’ˆë“¤ì´ ì£¼ëª©ë°›ì„ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤:",
                'recommendations': [
                    {'category': 'ì•„ìš°í„°', 'name': 'ì˜¤ë²„ì‚¬ì´ì¦ˆ ì¬í‚·', 'reason': 'S/S ì‹œì¦Œ íŠ¸ë Œë“œ ë¶€ìƒ ì¤‘'},
                    {'category': 'ìƒì˜', 'name': 'ë‹ˆíŠ¸ ë² ìŠ¤íŠ¸', 'reason': 'ì–¸ê¸‰ëŸ‰ ì „ì›” ëŒ€ë¹„ 82% ì¦ê°€'},
                    {'category': 'í•˜ì˜', 'name': 'ì™€ì´ë“œ íŒ¬ì¸ ', 'reason': 'ì§€ì†ì ì¸ ì¸ê¸° ìœ ì§€'}
                ]
            },
            'sellingInsight': {
                'summary': "í˜„ì¬ íŠ¸ë Œë“œì™€ ê²€ìƒ‰ëŸ‰ì„ ë¶„ì„í•œ ê²°ê³¼, ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ…ì´ íš¨ê³¼ì ì¼ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤:",
                'keywords': [
                    {'text': 'ë¯¸ë‹ˆë©€ë£©', 'stats': 'ê²€ìƒ‰ëŸ‰ ì¦ê°€ìœ¨: +45%'},
                    {'text': 'ì˜¤ë²„í•', 'stats': 'ê²€ìƒ‰ëŸ‰ ì¦ê°€ìœ¨: +38%'},
                    {'text': 'ë‰´íŠ¸ë¡œ', 'stats': 'ê²€ìƒ‰ëŸ‰ ì¦ê°€ìœ¨: +27%'}
                ]
            },
            'keywordReports': [
                {
                    'keyword': top_keywords[0][0] if top_keywords else 'í‚¤ì›Œë“œ1',
                    'summary': f"ì´ í‚¤ì›Œë“œëŠ” ìµœê·¼ {period} ë™ì•ˆ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, íŠ¹íˆ 20-30ëŒ€ ì—¬ì„± ì†Œë¹„ìë“¤ ì‚¬ì´ì—ì„œ ì¸ê¸°ê°€ ë†’ìŠµë‹ˆë‹¤. ê´€ë ¨ ì œí’ˆì˜ ìˆ˜ìš”ëŠ” ì „ì›” ëŒ€ë¹„ 25% ì¦ê°€í–ˆìœ¼ë©°, ì†Œì…œ ë¯¸ë””ì–´ì—ì„œì˜ ì–¸ê¸‰ëŸ‰ë„ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤."
                },
                {
                    'keyword': top_keywords[1][0] if len(top_keywords) > 1 else 'í‚¤ì›Œë“œ2',
                    'summary': f"ì´ í‚¤ì›Œë“œëŠ” ìµœê·¼ {period} ë™ì•ˆ íŠ¸ë Œë“œë¡œ ë¶€ìƒí•˜ì˜€ìœ¼ë©°, ì¸ìŠ¤íƒ€ê·¸ë¨ì—ì„œ ê´€ë ¨ í•´ì‹œíƒœê·¸ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ 10-20ëŒ€ MZì„¸ëŒ€ê°€ ê´€ì‹¬ì„ ë³´ì´ê³  ìˆìœ¼ë©°, ê´€ë ¨ ì½˜í…ì¸ ì˜ ì°¸ì—¬ìœ¨ë„ ë†’ìŠµë‹ˆë‹¤."
                },
                {
                    'keyword': top_keywords[2][0] if len(top_keywords) > 2 else 'í‚¤ì›Œë“œ3',
                    'summary': f"ì´ í‚¤ì›Œë“œëŠ” ìµœê·¼ {period} ë™ì•ˆ ì§€ì†ì ì¸ ê´€ì‹¬ì„ ë°›ê³  ìˆìœ¼ë©°, íŠ¹íˆ ìœ íŠœë¸Œì™€ ê°™ì€ ì˜ìƒ ì½˜í…ì¸ ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚¨ì„± ì†Œë¹„ìì¸µì—ì„œë„ ì¸ê¸°ê°€ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤."
                },
                {
                    'keyword': top_keywords[3][0] if len(top_keywords) > 3 else 'í‚¤ì›Œë“œ4',
                    'summary': "í•´ë‹¹ í‚¤ì›Œë“œëŠ” ê³„ì ˆì  ìš”ì¸ê³¼ ì—°ê´€ì´ ìˆìœ¼ë©°, ìµœê·¼ íŒ¨ì…˜ ì¸í”Œë£¨ì–¸ì„œë“¤ì˜ ì†Œê°œë¡œ ì¸í•´ ë…¸ì¶œì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ 30-40ëŒ€ ì†Œë¹„ìì¸µì—ì„œ ë°˜ì‘ì´ ì¢‹ìŠµë‹ˆë‹¤."
                },
                {
                    'keyword': top_keywords[4][0] if len(top_keywords) > 4 else 'í‚¤ì›Œë“œ5',
                    'summary': "ì´ í‚¤ì›Œë“œëŠ” ìµœê·¼ ì…€ëŸ½ë“¤ì˜ ì°©ìš©ìœ¼ë¡œ ì¸í•´ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, ëŸ­ì…”ë¦¬ ë¸Œëœë“œì™€ SPA ë¸Œëœë“œ ëª¨ë‘ì—ì„œ ê´€ë ¨ ì œí’ˆì´ ì¶œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ê²©ëŒ€ë³„ ë‹¤ì–‘í•œ ì˜µì…˜ì´ ì†Œë¹„ìë“¤ì—ê²Œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤."
                }
            ]
        }
        
        # ìº˜ë¦°ë” ì´ë²¤íŠ¸ ì˜ˆì‹œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DBì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        events = [
            {
                'date': '2025-04-03',
                'title': 'ì„œìš¸íŒ¨ì…˜ìœ„í¬ 2025 F/W',
                'location': 'ë™ëŒ€ë¬¸ DDP',
                'duration': '2025-04-03 ~ 2025-04-08'
            },
            {
                'date': '2025-04-15',
                'title': 'íŒ¨ì…˜ ì•„íŠ¸ ì „ì‹œíšŒ',
                'location': 'ì„±ìˆ˜ë™ SíŒ©í† ë¦¬',
                'duration': '2025-04-15 ~ 2025-04-20'
            },
            {
                'date': '2025-04-25',
                'title': 'ì§€ì†ê°€ëŠ¥ íŒ¨ì…˜ í¬ëŸ¼',
                'location': 'ì½”ì—‘ìŠ¤ ì»¨í¼ëŸ°ìŠ¤ë£¸',
                'duration': '2025-04-25'
            }
        ]
        
        response_data['events'] = events
        
        return jsonify(response_data)
    
    except Exception as e:
        logger.error(f"í†µí•© íŠ¸ë Œë“œ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})

@app.route('/api/calendar-events')
def calendar_events():
    """íŒ¨ì…˜ ê´€ë ¨ ì¼ì • API"""
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„°
        year = request.args.get('year', datetime.now().year, type=int)
        month = request.args.get('month', datetime.now().month, type=int)
        
        logger.info(f"ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìš”ì²­: ë…„={year}, ì›”={month}")
        
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DBì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        events = []
        
        # 4ì›” ì˜ˆì‹œ ë°ì´í„°
        if month == 4 and year == 2025:
            events = [
                {
                    'date': datetime(2025, 4, 3).strftime('%Y-%m-%d'),
                    'title': 'ì„œìš¸íŒ¨ì…˜ìœ„í¬ 2025 F/W',
                    'location': 'ë™ëŒ€ë¬¸ DDP',
                    'duration': '2025-04-03 ~ 2025-04-08'
                },
                {
                    'date': datetime(2025, 4, 15).strftime('%Y-%m-%d'),
                    'title': 'íŒ¨ì…˜ ì•„íŠ¸ ì „ì‹œíšŒ',
                    'location': 'ì„±ìˆ˜ë™ SíŒ©í† ë¦¬',
                    'duration': '2025-04-15 ~ 2025-04-20'
                },
                {
                    'date': datetime(2025, 4, 25).strftime('%Y-%m-%d'),
                    'title': 'ì§€ì†ê°€ëŠ¥ íŒ¨ì…˜ í¬ëŸ¼',
                    'location': 'ì½”ì—‘ìŠ¤ ì»¨í¼ëŸ°ìŠ¤ë£¸',
                    'duration': '2025-04-25'
                }
            ]
        # 5ì›” ì˜ˆì‹œ ë°ì´í„°
        elif month == 5 and year == 2025:
            events = [
                {
                    'date': datetime(2025, 5, 10).strftime('%Y-%m-%d'),
                    'title': 'ë©”íŠ¸ ê°ˆë¼ 2025',
                    'location': 'ë‰´ìš• ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë®¤ì§€ì—„',
                    'duration': '2025-05-10'
                },
                {
                    'date': datetime(2025, 5, 20).strftime('%Y-%m-%d'),
                    'title': 'íŒ¨ì…˜ ì„œìŠ¤í…Œì´ë„ˆë¹Œë¦¬í‹° ì „ì‹œíšŒ',
                    'location': 'ì„œìš¸ ì˜ˆìˆ ì˜ì „ë‹¹',
                    'duration': '2025-05-20 ~ 2025-05-25'
                }
            ]
        
        return jsonify({
            'year': year,
            'month': month,
            'events': events
        })
    
    except Exception as e:
        logger.error(f"ìº˜ë¦°ë” ì´ë²¤íŠ¸ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)})


@app.route('/api/ask', methods=['POST'])
def ask():
    data = request.json
    query = data.get('query', '')
    data_source = data.get('data_source', 'magazine')
    start_date = data.get('start_date')
    end_date = data.get('end_date')
    
    try:
        # RAG ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ í˜¸ì¶œ
        response = rag_system.answer_query(
            query=query,
            data_source=data_source,
            start_date=start_date,
            end_date=end_date
        )
        return jsonify({'response': response})
    except Exception as e:
        app.logger.error(f"ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({'error': f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500


@app.errorhandler(404)
def page_not_found(e):
    """404 ì˜¤ë¥˜ ì²˜ë¦¬"""
    error_message = "í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì •ì  íŒŒì¼ ìš”ì²­ ì˜¤ë¥˜ì¸ ê²½ìš° ë” êµ¬ì²´ì ì¸ ë©”ì‹œì§€ ì œê³µ
    if request.path.startswith('/static/'):
        logger.warning(f"ì •ì  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {request.path}")
        error_message = "ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # íŠ¹ì • ê²½ë¡œì— ëŒ€í•œ ë¬¸ì œì¸ ê²½ìš° ëŒ€ì•ˆ ì œê³µ
        if 'images/competitor/' in request.path:
            error_message += " í•´ë‹¹ ê¸°ê°„ì— ìƒì„±ëœ ì°¨íŠ¸ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ ë³´ì„¸ìš”."
    
    return render_template('error.html', 
                          error=error_message,
                          error_code=404), 404

@app.errorhandler(500)
def server_error(e):
    """500 ì˜¤ë¥˜ ì²˜ë¦¬"""
    logger.error(f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    error_message = "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ì •ì  íŒŒì¼ ê´€ë ¨ ì˜¤ë¥˜ì¸ ê²½ìš°
    if hasattr(e, 'description') and 'image' in str(e).lower():
        error_message = "ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ ë³´ì„¸ìš”."

    return render_template('error.html',
                           error=error_message,
                           error_code=500), 500

if __name__ == '__main__':
    # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê²½ê³  ì¶œë ¥
    if not rag_system_initialized:
        print("\n" + "*"*50)
        print("ê²½ê³ : RAG ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ì±—ë´‡(/api/ask) ë° ê´€ë ¨ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("core/config.pyì˜ RAG ê´€ë ¨ ê²½ë¡œ ì„¤ì • ë° ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print("*"*50 + "\n")
    app.run(debug=True, port=5001)